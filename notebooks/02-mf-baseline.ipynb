{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":3949614,"sourceType":"datasetVersion","datasetId":2344310},{"sourceId":260200709,"sourceType":"kernelVersion"}],"dockerImageVersionId":31089,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input/movielens-25m-dataset'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-09-05T20:57:27.205439Z","iopub.execute_input":"2025-09-05T20:57:27.206407Z","iopub.status.idle":"2025-09-05T20:57:27.217780Z","shell.execute_reply.started":"2025-09-05T20:57:27.206365Z","shell.execute_reply":"2025-09-05T20:57:27.216860Z"}},"outputs":[{"name":"stdout","text":"/kaggle/input/movielens-25m-dataset/ml-25m-README.html\n/kaggle/input/movielens-25m-dataset/ml-25m/ml-25m/movies.csv\n/kaggle/input/movielens-25m-dataset/ml-25m/ml-25m/ratings.csv\n/kaggle/input/movielens-25m-dataset/ml-25m/ml-25m/genome-tags.csv\n/kaggle/input/movielens-25m-dataset/ml-25m/ml-25m/README.txt\n/kaggle/input/movielens-25m-dataset/ml-25m/ml-25m/genome-scores.csv\n/kaggle/input/movielens-25m-dataset/ml-25m/ml-25m/tags.csv\n/kaggle/input/movielens-25m-dataset/ml-25m/ml-25m/links.csv\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"import numpy as np, pandas as pd, scipy.sparse as sp\nfrom scipy.sparse.linalg import svds\nimport matplotlib.pyplot as plt\nimport os, gc\n\ntrain = pd.read_parquet(\"/kaggle/input/movielens-25m-recsys/outputs/parquet/train.parquet\")\nvalid = pd.read_parquet(\"/kaggle/input/movielens-25m-recsys/outputs/parquet/valid_label.parquet\")\ntest  = pd.read_parquet(\"/kaggle/input/movielens-25m-recsys/outputs/parquet/test_label.parquet\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-05T20:57:46.580272Z","iopub.execute_input":"2025-09-05T20:57:46.580568Z","iopub.status.idle":"2025-09-05T20:57:47.130630Z","shell.execute_reply.started":"2025-09-05T20:57:46.580549Z","shell.execute_reply":"2025-09-05T20:57:47.129481Z"}},"outputs":[],"execution_count":5},{"cell_type":"markdown","source":"## 1) Create sparse matrix â†’ Learn latent factors using SVD","metadata":{}},{"cell_type":"code","source":"n_users = train[\"u\"].max() + 1\nn_items = train[\"i\"].max() + 1\n\nR = sp.coo_matrix(\n    (train[\"rating\"], (train[\"u\"], train[\"i\"])),\n    shape=(n_users, n_items)\n).tocsr()\n\nK = 64\nu_f, s, vt = svds(R.astype(\"float32\"), k=K)\n\nS = np.diag(s)\nU = u_f @ S      # Users embedding vector (n_users, K)\nV = vt.T         # Items embedding vector (n_items, K)\n\n# Function to predict how much a user will like an item \n# by taking the dot product of their embedding vectors.\ndef mf_score(u_idx, i_idx):\n    # embedding vector(s) of selected users * embedding vector(s) of selected items\n    return (U[u_idx] * V[i_idx]).sum(axis=1)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-05T21:00:35.099325Z","iopub.execute_input":"2025-09-05T21:00:35.099751Z","iopub.status.idle":"2025-09-05T21:00:40.886489Z","shell.execute_reply.started":"2025-09-05T21:00:35.099717Z","shell.execute_reply":"2025-09-05T21:00:40.885083Z"}},"outputs":[],"execution_count":6},{"cell_type":"markdown","source":"## 3) TOP K","metadata":{}},{"cell_type":"code","source":"TOPK = 50\nBATCH = 500\nOUT_DIR = \"/kaggle/working/batch\"\nos.makedirs(OUT_DIR, exist_ok=True)\n\n# Indices dictioniary if the users' \"seen\" items \nseen_dict = (\n    train.groupby(\"u\")[\"i\"].apply(lambda x: x.values.astype(np.int64)).to_dict()\n)\n\nVt = V.T.astype(np.float32, copy=False)    # (K, n_items)\n\nall_users = np.arange(n_users, dtype=np.int64)\npart_files = []\nfor bi, start in enumerate(range(0, n_users, BATCH)):\n    end = min(start + BATCH, n_users)\n    batch_users = all_users[start:end]\n    Ubatch = U[batch_users].astype(np.float32, copy=False)\n\n    scores = Ubatch @ Vt     # (batch, n_items)\n\n    # Mask as -np.inf using seen_dict\n    for j, u in enumerate(batch_users):\n        seen_items = seen_dict.get(u, None)\n        if seen_items is not None and len(seen_items) > 0:\n            scores[j, seen_items] = -np.inf\n\n    idx_topk = np.argpartition(scores, -TOPK, axis=1)[:, -TOPK:]          # indices for the top K items in each user's row (batch, TOPK)\n    part_scores = np.take_along_axis(scores, idx_topk, axis=1)            # scores at the idx_topk (batch, TOPK)\n    order_in_part = np.argsort(-part_scores, axis=1)                      # \"sorting index\" of topk scores\n    \n    topk_idx_sorted = np.take_along_axis(idx_topk, order_in_part, axis=1) # item indices from sorted (batch, TOPK)\n    topk_scores = np.take_along_axis(part_scores, order_in_part, axis=1)  # sorted scores (batch, TOPK)\n\n    uu = np.repeat(batch_users, TOPK).astype(np.int64)\n    ii = topk_idx_sorted.reshape(-1).astype(np.int64)   # flattened TOPK idx\n    ss = topk_scores.reshape(-1).astype(np.float32)     # flattened TOPK scores\n    \n    df_part = pd.DataFrame({\"u\": uu, \"i\": ii, \"mf_score\": ss})\n\n    part_path = f\"{OUT_DIR}/candidates_part_{bi:03d}.parquet\"\n    df_part.to_parquet(part_path, index=False)\n    part_files.append(part_path)\n\n    del scores, idx_topk, part_scores, order_in_part, topk_idx_sorted, topk_scores, df_part, uu, ii, ss\n    gc.collect()\n\nprint(\"Baseline candidate files saved:\", len(part_files))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-05T21:03:06.920228Z","iopub.execute_input":"2025-09-05T21:03:06.920598Z","iopub.status.idle":"2025-09-05T21:03:26.232206Z","shell.execute_reply.started":"2025-09-05T21:03:06.920575Z","shell.execute_reply":"2025-09-05T21:03:26.231211Z"}},"outputs":[{"name":"stdout","text":"Baseline candidate files saved: 75\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}